{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import itertools\n",
    "import colorsys\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "from config import Config\n",
    "from model import MaskRCNN\n",
    "from visualize import display_instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(Config):\n",
    "    \"\"\"\n",
    "    Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 2  # background + 2 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_MIN_DIM = 1024\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "    IMAGE_CHANNEL_COUNT = 3\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 200\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(MODEL_DIR,config):\n",
    "    \n",
    "    # Recreate the model in inference mode\n",
    "    model = MaskRCNN(mode=\"inference\", \n",
    "                              config=config,\n",
    "                              model_dir=MODEL_DIR)\n",
    "\n",
    "    # Get path to saved weights\n",
    "    # Either set a specific path or find last trained weights\n",
    "\n",
    "    model_path = os.path.join(MODEL_DIR)\n",
    "    # model_path = os.path.join(ROOT_DIR, r'/logs')\n",
    "    # model_path = model.find_last()\n",
    "\n",
    "    # Load trained weights\n",
    "    print(\"Loading weights from \", model_path)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "    return model\n",
    "def prediction(model, image):\n",
    "    # 모델 예측\n",
    "    results = model.detect([image], verbose=1)\n",
    "    r = results[0]\n",
    "    return r\n",
    "\n",
    "def get_overlay(image, boxes, masks, class_ids, class_names,\n",
    "                      scores=None, title=\"\",\n",
    "                    show_bbox=True,colors=None, captions=None):\n",
    "                      \n",
    "    \"\"\"\n",
    "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
    "    masks: [height, width, num_instances]\n",
    "    class_ids: [num_instances]\n",
    "    class_names: list of class names of the dataset\n",
    "    scores: (optional) confidence scores for each box\n",
    "    title: (optional) Figure title\n",
    "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
    "    figsize: (optional) the size of the image\n",
    "    colors: (optional) An array or colors to use with each object\n",
    "    captions: (optional) A list of strings to use as captions for each object\n",
    "    \"\"\"\n",
    "    # Number of instances\n",
    "    N = boxes.shape[0]\n",
    "    if not N:\n",
    "        print(\"\\n*** No instances to display *** \\n\")\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "\n",
    "    # If no axis is passed, create one and automatically call show()\n",
    "#     auto_show = False\n",
    "#     if not ax:\n",
    "#         _, ax = plt.subplots(1, figsize=figsize)\n",
    "#         auto_show = True\n",
    "\n",
    "    # Generate random colors\n",
    "    #colors = colors or random_colors(N)\n",
    "    colors = colors\n",
    "\n",
    "    # Show area outside image boundaries.\n",
    "    height, width = image.shape[:2]\n",
    "#     ax.set_ylim(height + 10, -10)\n",
    "#     ax.set_xlim(-10, width + 10)\n",
    "#     ax.axis('off')\n",
    "#     ax.set_title(title)\n",
    "\n",
    "    masked_image = image.astype(np.uint8).copy()\n",
    "    for i in range(N):\n",
    "        color = (1,1,1)\n",
    "\n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        if show_bbox:\n",
    "#             p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
    "#                                 alpha=0.7, linestyle=\"dashed\",\n",
    "#                                 edgecolor=color, facecolor='none')\n",
    "#             ax.add_patch(p)\n",
    "            cv.rectangle(masked_image,(x1,y1),(x2,y2),color,10)\n",
    "            \n",
    "\n",
    "        # Label\n",
    "        if not captions:\n",
    "            class_id = class_ids[i]\n",
    "            score = scores[i] if scores is not None else None\n",
    "            label = class_names[class_id]\n",
    "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "        else:\n",
    "            caption = captions[i]\n",
    "        cv.putText(masked_image,caption,(x1, y1 + 8),cv.FONT_HERSHEY_COMPLEX,3,(0,0,0),3)\n",
    "#         ax.text(x1, y1 + 8, caption,\n",
    "#                 color='w', size=11, backgroundcolor=\"none\")\n",
    "\n",
    "        # Mask\n",
    "        mask = masks[:, :, i]\n",
    "#         if show_mask:\n",
    "#             masked_image = apply_mask(masked_image, mask, color)\n",
    "\n",
    "        # Mask Polygon\n",
    "        # Pad to ensure proper polygons for masks that touch image edges.\n",
    "        padded_mask = np.zeros(\n",
    "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        contours = find_contours(padded_mask, 0.5)\n",
    "        for verts in contours:\n",
    "            # Subtract the padding and flip (y, x) to (x, y)\n",
    "            verts = np.fliplr(verts) - 1\n",
    "            masked_image = cv.polylines(masked_image,np.int32([verts]),True,(0,0,0),7)\n",
    "#             p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
    "#             ax.add_patch(p)\n",
    "            \n",
    "#    ax.imshow(masked_image.astype(np.uint8))\n",
    "#     if auto_show:\n",
    "#         plt.show()\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\micke\\Miniconda3\\envs\\mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Gproject\\Codes\\GFollow2020\\Segmentation\\for_web\\model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Gproject\\Codes\\GFollow2020\\Segmentation\\for_web\\model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Gproject\\Codes\\GFollow2020\\Segmentation\\for_web\\model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From D:\\Gproject\\Codes\\GFollow2020\\Segmentation\\for_web\\model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Gproject\\Codes\\GFollow2020\\Segmentation\\for_web\\model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Gproject\\Codes\\GFollow2020\\Segmentation\\for_web\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Loading weights from  ../logs/Segment_model.h5\n",
      "Processing 1 images\n",
      "image                    shape: (4419, 3328, 3)       min:    0.00000  max:  237.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  132.10000  float64\n",
      "image_metas              shape: (1, 15)               min:    0.00000  max: 4419.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "WARNING:tensorflow:From C:\\Users\\micke\\Miniconda3\\envs\\mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(r'../logs/Segment_model.h5',InferenceConfig())\n",
    "img = cv.imread(r'E:\\DataSet\\CBIS-DDSM\\Crop_train\\Mass-Training_P_01138_RIGHT_CC_full.png')\n",
    "ans = prediction(model,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf idx : 4\n"
     ]
    }
   ],
   "source": [
    "conf = 0.9\n",
    "idx = 0\n",
    "for i in range(len(ans['scores'])):\n",
    "    if ans['scores'][i] > conf:\n",
    "        idx +=1\n",
    "    else : break\n",
    "print(\"Conf idx :\", idx)\n",
    "a = get_overlay(img, ans['rois'][:idx],ans['masks'][...,:idx],ans['class_ids'][:idx],['BG','Calc','Mass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
